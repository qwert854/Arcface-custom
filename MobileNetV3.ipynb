{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "import os\n",
    "import torchvision.datasets as dset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#패스 지정\n",
    "dataset_path = \"/home/sw/Desktop/py/dataset\"\n",
    "model_weight_save_path = \"/home/sw/Desktop/py/save/\"\n",
    "num_classes = 13\n",
    "\n",
    "batch_size = 128\n",
    "num_workers = 4\n",
    "learning_rate = 0.1\n",
    "layers = 50\n",
    "epoch = 201\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 및 테스트데이터 로드\n",
    "traindir = os.path.join(dataset_path, '/home/sw/Desktop/py/dataset/train')\n",
    "testdir = os.path.join(dataset_path, '/home/sw/Desktop/py/dataset/train')\n",
    "\n",
    "#normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(\n",
    "    traindir,\n",
    "    transforms.Compose([\n",
    "        transforms.Resize(32),\n",
    "        transforms.ToTensor(),\n",
    "        #normalize\n",
    "    ]))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True,\n",
    "    num_workers=num_workers, pin_memory=True, drop_last=False)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.ImageFolder(testdir, transforms.Compose([\n",
    "        transforms.Resize(32),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        #normalize\n",
    "    ])),\n",
    "    batch_size=batch_size, shuffle=False,\n",
    "    num_workers=num_workers, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenetv3:\n",
      " MobileNetV3(\n",
      "  (features): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): Hswish()\n",
      "    )\n",
      "    (1): MobileBottleneck(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)\n",
      "        (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): SEModule(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc): Sequential(\n",
      "            (0): Linear(in_features=16, out_features=4, bias=False)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=4, out_features=16, bias=False)\n",
      "            (3): Hsigmoid()\n",
      "          )\n",
      "        )\n",
      "        (6): ReLU(inplace=True)\n",
      "        (7): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (8): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (2): MobileBottleneck(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(16, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(72, 72, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=72, bias=False)\n",
      "        (4): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Identity()\n",
      "        (6): ReLU(inplace=True)\n",
      "        (7): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (8): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (3): MobileBottleneck(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(24, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(88, 88, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=88, bias=False)\n",
      "        (4): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Identity()\n",
      "        (6): ReLU(inplace=True)\n",
      "        (7): Conv2d(88, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (8): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (4): MobileBottleneck(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): Hswish()\n",
      "        (3): Conv2d(96, 96, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=96, bias=False)\n",
      "        (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): SEModule(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc): Sequential(\n",
      "            (0): Linear(in_features=96, out_features=24, bias=False)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=24, out_features=96, bias=False)\n",
      "            (3): Hsigmoid()\n",
      "          )\n",
      "        )\n",
      "        (6): Hswish()\n",
      "        (7): Conv2d(96, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (8): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (5): MobileBottleneck(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): Hswish()\n",
      "        (3): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
      "        (4): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): SEModule(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc): Sequential(\n",
      "            (0): Linear(in_features=240, out_features=60, bias=False)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=60, out_features=240, bias=False)\n",
      "            (3): Hsigmoid()\n",
      "          )\n",
      "        )\n",
      "        (6): Hswish()\n",
      "        (7): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (8): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (6): MobileBottleneck(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): Hswish()\n",
      "        (3): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
      "        (4): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): SEModule(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc): Sequential(\n",
      "            (0): Linear(in_features=240, out_features=60, bias=False)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=60, out_features=240, bias=False)\n",
      "            (3): Hsigmoid()\n",
      "          )\n",
      "        )\n",
      "        (6): Hswish()\n",
      "        (7): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (8): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (7): MobileBottleneck(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): Hswish()\n",
      "        (3): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "        (4): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): SEModule(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc): Sequential(\n",
      "            (0): Linear(in_features=120, out_features=30, bias=False)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=30, out_features=120, bias=False)\n",
      "            (3): Hsigmoid()\n",
      "          )\n",
      "        )\n",
      "        (6): Hswish()\n",
      "        (7): Conv2d(120, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (8): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (8): MobileBottleneck(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): Hswish()\n",
      "        (3): Conv2d(144, 144, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=144, bias=False)\n",
      "        (4): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): SEModule(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc): Sequential(\n",
      "            (0): Linear(in_features=144, out_features=36, bias=False)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=36, out_features=144, bias=False)\n",
      "            (3): Hsigmoid()\n",
      "          )\n",
      "        )\n",
      "        (6): Hswish()\n",
      "        (7): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (8): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (9): MobileBottleneck(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): Hswish()\n",
      "        (3): Conv2d(288, 288, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=288, bias=False)\n",
      "        (4): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): SEModule(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc): Sequential(\n",
      "            (0): Linear(in_features=288, out_features=72, bias=False)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=72, out_features=288, bias=False)\n",
      "            (3): Hsigmoid()\n",
      "          )\n",
      "        )\n",
      "        (6): Hswish()\n",
      "        (7): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (8): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (10): MobileBottleneck(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): Hswish()\n",
      "        (3): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
      "        (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): SEModule(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc): Sequential(\n",
      "            (0): Linear(in_features=576, out_features=144, bias=False)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=144, out_features=576, bias=False)\n",
      "            (3): Hsigmoid()\n",
      "          )\n",
      "        )\n",
      "        (6): Hswish()\n",
      "        (7): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (8): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (11): MobileBottleneck(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): Hswish()\n",
      "        (3): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
      "        (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): SEModule(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc): Sequential(\n",
      "            (0): Linear(in_features=576, out_features=144, bias=False)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=144, out_features=576, bias=False)\n",
      "            (3): Hsigmoid()\n",
      "          )\n",
      "        )\n",
      "        (6): Hswish()\n",
      "        (7): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (8): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (12): Sequential(\n",
      "      (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): Hswish()\n",
      "    )\n",
      "    (13): AdaptiveAvgPool2d(output_size=1)\n",
      "    (14): Conv2d(576, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (15): Hswish()\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.8, inplace=False)\n",
      "    (1): Linear(in_features=1280, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n",
      "Total params: 2.94M\n",
      "Register FLOP counter for module Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "Not implemented for  BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Not implemented for  Hswish()\n",
      "Register FLOP counter for module Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "Not implemented for  BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Not implemented for  ReLU(inplace=True)\n",
      "Register FLOP counter for module Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)\n",
      "Not implemented for  BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Not implemented for  AdaptiveAvgPool2d(output_size=1)\n",
      "Register FLOP counter for module Linear(in_features=16, out_features=4, bias=False)\n",
      "Not implemented for  ReLU(inplace=True)\n",
      "Register FLOP counter for module Linear(in_features=4, out_features=16, bias=False)\n",
      "Not implemented for  Hsigmoid()\n",
      "Not implemented for  ReLU(inplace=True)\n",
      "Register FLOP counter for module Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "Not implemented for  BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Register FLOP counter for module Conv2d(16, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "Not implemented for  BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Not implemented for  ReLU(inplace=True)\n",
      "Register FLOP counter for module Conv2d(72, 72, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=72, bias=False)\n",
      "Not implemented for  BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Not implemented for  Identity()\n",
      "Not implemented for  ReLU(inplace=True)\n",
      "Register FLOP counter for module Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "Not implemented for  BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Register FLOP counter for module Conv2d(24, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "Not implemented for  BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Not implemented for  ReLU(inplace=True)\n",
      "Register FLOP counter for module Conv2d(88, 88, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=88, bias=False)\n",
      "Not implemented for  BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Not implemented for  Identity()\n",
      "Not implemented for  ReLU(inplace=True)\n",
      "Register FLOP counter for module Conv2d(88, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "Not implemented for  BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Register FLOP counter for module Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "Not implemented for  BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Not implemented for  Hswish()\n",
      "Register FLOP counter for module Conv2d(96, 96, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=96, bias=False)\n",
      "Not implemented for  BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Not implemented for  AdaptiveAvgPool2d(output_size=1)\n",
      "Register FLOP counter for module Linear(in_features=96, out_features=24, bias=False)\n",
      "Not implemented for  ReLU(inplace=True)\n",
      "Register FLOP counter for module Linear(in_features=24, out_features=96, bias=False)\n",
      "Not implemented for  Hsigmoid()\n",
      "Not implemented for  Hswish()\n",
      "Register FLOP counter for module Conv2d(96, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "Not implemented for  BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Register FLOP counter for module Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "Not implemented for  BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Not implemented for  Hswish()\n",
      "Register FLOP counter for module Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
      "Not implemented for  BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Not implemented for  AdaptiveAvgPool2d(output_size=1)\n",
      "Register FLOP counter for module Linear(in_features=240, out_features=60, bias=False)\n",
      "Not implemented for  ReLU(inplace=True)\n",
      "Register FLOP counter for module Linear(in_features=60, out_features=240, bias=False)\n",
      "Not implemented for  Hsigmoid()\n",
      "Not implemented for  Hswish()\n",
      "Register FLOP counter for module Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "Not implemented for  BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Register FLOP counter for module Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "Not implemented for  BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Not implemented for  Hswish()\n",
      "Register FLOP counter for module Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
      "Not implemented for  BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Not implemented for  AdaptiveAvgPool2d(output_size=1)\n",
      "Register FLOP counter for module Linear(in_features=240, out_features=60, bias=False)\n",
      "Not implemented for  ReLU(inplace=True)\n",
      "Register FLOP counter for module Linear(in_features=60, out_features=240, bias=False)\n",
      "Not implemented for  Hsigmoid()\n",
      "Not implemented for  Hswish()\n",
      "Register FLOP counter for module Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "Not implemented for  BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Register FLOP counter for module Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "Not implemented for  BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Not implemented for  Hswish()\n",
      "Register FLOP counter for module Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "Not implemented for  BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Not implemented for  AdaptiveAvgPool2d(output_size=1)\n",
      "Register FLOP counter for module Linear(in_features=120, out_features=30, bias=False)\n",
      "Not implemented for  ReLU(inplace=True)\n",
      "Register FLOP counter for module Linear(in_features=30, out_features=120, bias=False)\n",
      "Not implemented for  Hsigmoid()\n",
      "Not implemented for  Hswish()\n",
      "Register FLOP counter for module Conv2d(120, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "Not implemented for  BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Register FLOP counter for module Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "Not implemented for  BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Not implemented for  Hswish()\n",
      "Register FLOP counter for module Conv2d(144, 144, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=144, bias=False)\n",
      "Not implemented for  BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Not implemented for  AdaptiveAvgPool2d(output_size=1)\n",
      "Register FLOP counter for module Linear(in_features=144, out_features=36, bias=False)\n",
      "Not implemented for  ReLU(inplace=True)\n",
      "Register FLOP counter for module Linear(in_features=36, out_features=144, bias=False)\n",
      "Not implemented for  Hsigmoid()\n",
      "Not implemented for  Hswish()\n",
      "Register FLOP counter for module Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "Not implemented for  BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Register FLOP counter for module Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "Not implemented for  BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Not implemented for  Hswish()\n",
      "Register FLOP counter for module Conv2d(288, 288, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=288, bias=False)\n",
      "Not implemented for  BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Not implemented for  AdaptiveAvgPool2d(output_size=1)\n",
      "Register FLOP counter for module Linear(in_features=288, out_features=72, bias=False)\n",
      "Not implemented for  ReLU(inplace=True)\n",
      "Register FLOP counter for module Linear(in_features=72, out_features=288, bias=False)\n",
      "Not implemented for  Hsigmoid()\n",
      "Not implemented for  Hswish()\n",
      "Register FLOP counter for module Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "Not implemented for  BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Register FLOP counter for module Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "Not implemented for  BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Not implemented for  Hswish()\n",
      "Register FLOP counter for module Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
      "Not implemented for  BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Not implemented for  AdaptiveAvgPool2d(output_size=1)\n",
      "Register FLOP counter for module Linear(in_features=576, out_features=144, bias=False)\n",
      "Not implemented for  ReLU(inplace=True)\n",
      "Register FLOP counter for module Linear(in_features=144, out_features=576, bias=False)\n",
      "Not implemented for  Hsigmoid()\n",
      "Not implemented for  Hswish()\n",
      "Register FLOP counter for module Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "Not implemented for  BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Register FLOP counter for module Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "Not implemented for  BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Not implemented for  Hswish()\n",
      "Register FLOP counter for module Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
      "Not implemented for  BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Not implemented for  AdaptiveAvgPool2d(output_size=1)\n",
      "Register FLOP counter for module Linear(in_features=576, out_features=144, bias=False)\n",
      "Not implemented for  ReLU(inplace=True)\n",
      "Register FLOP counter for module Linear(in_features=144, out_features=576, bias=False)\n",
      "Not implemented for  Hsigmoid()\n",
      "Not implemented for  Hswish()\n",
      "Register FLOP counter for module Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "Not implemented for  BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Register FLOP counter for module Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "Not implemented for  BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Not implemented for  Hswish()\n",
      "Not implemented for  AdaptiveAvgPool2d(output_size=1)\n",
      "Register FLOP counter for module Conv2d(576, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "Not implemented for  Hswish()\n",
      "Not implemented for  Dropout(p=0.8, inplace=False)\n",
      "Register FLOP counter for module Linear(in_features=1280, out_features=1000, bias=True)\n",
      "Total params: 2.94M\n",
      "Total flops: 62.59M\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "__all__ = ['MobileNetV3', 'mobilenetv3']\n",
    "\n",
    "\n",
    "def conv_bn(inp, oup, stride, conv_layer=nn.Conv2d, norm_layer=nn.BatchNorm2d, nlin_layer=nn.ReLU):\n",
    "    return nn.Sequential(\n",
    "        conv_layer(inp, oup, 3, stride, 1, bias=False),\n",
    "        norm_layer(oup),\n",
    "        nlin_layer(inplace=True)\n",
    "    )\n",
    "\n",
    "\n",
    "def conv_1x1_bn(inp, oup, conv_layer=nn.Conv2d, norm_layer=nn.BatchNorm2d, nlin_layer=nn.ReLU):\n",
    "    return nn.Sequential(\n",
    "        conv_layer(inp, oup, 1, 1, 0, bias=False),\n",
    "        norm_layer(oup),\n",
    "        nlin_layer(inplace=True)\n",
    "    )\n",
    "\n",
    "\n",
    "class Hswish(nn.Module):\n",
    "    def __init__(self, inplace=True):\n",
    "        super(Hswish, self).__init__()\n",
    "        self.inplace = inplace\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x * F.relu6(x + 3., inplace=self.inplace) / 6.\n",
    "\n",
    "\n",
    "class Hsigmoid(nn.Module):\n",
    "    def __init__(self, inplace=True):\n",
    "        super(Hsigmoid, self).__init__()\n",
    "        self.inplace = inplace\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.relu6(x + 3., inplace=self.inplace) / 6.\n",
    "\n",
    "\n",
    "class SEModule(nn.Module):\n",
    "    def __init__(self, channel, reduction=4):\n",
    "        super(SEModule, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channel, channel // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channel // reduction, channel, bias=False),\n",
    "            Hsigmoid()\n",
    "            # nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1, 1)\n",
    "        return x * y.expand_as(x)\n",
    "\n",
    "\n",
    "class Identity(nn.Module):\n",
    "    def __init__(self, channel):\n",
    "        super(Identity, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "\n",
    "def make_divisible(x, divisible_by=8):\n",
    "    import numpy as np\n",
    "    return int(np.ceil(x * 1. / divisible_by) * divisible_by)\n",
    "\n",
    "\n",
    "class MobileBottleneck(nn.Module):\n",
    "    def __init__(self, inp, oup, kernel, stride, exp, se=False, nl='RE'):\n",
    "        super(MobileBottleneck, self).__init__()\n",
    "        assert stride in [1, 2]\n",
    "        assert kernel in [3, 5]\n",
    "        padding = (kernel - 1) // 2\n",
    "        self.use_res_connect = stride == 1 and inp == oup\n",
    "\n",
    "        conv_layer = nn.Conv2d\n",
    "        norm_layer = nn.BatchNorm2d\n",
    "        if nl == 'RE':\n",
    "            nlin_layer = nn.ReLU # or ReLU6\n",
    "        elif nl == 'HS':\n",
    "            nlin_layer = Hswish\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        if se:\n",
    "            SELayer = SEModule\n",
    "        else:\n",
    "            SELayer = Identity\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            # pw\n",
    "            conv_layer(inp, exp, 1, 1, 0, bias=False),\n",
    "            norm_layer(exp),\n",
    "            nlin_layer(inplace=True),\n",
    "            # dw\n",
    "            conv_layer(exp, exp, kernel, stride, padding, groups=exp, bias=False),\n",
    "            norm_layer(exp),\n",
    "            SELayer(exp),\n",
    "            nlin_layer(inplace=True),\n",
    "            # pw-linear\n",
    "            conv_layer(exp, oup, 1, 1, 0, bias=False),\n",
    "            norm_layer(oup),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.use_res_connect:\n",
    "            return x + self.conv(x)\n",
    "        else:\n",
    "            return self.conv(x)\n",
    "\n",
    "\n",
    "class MobileNetV3(nn.Module):\n",
    "    def __init__(self, n_class=1000, input_size=224, dropout=0.8, mode='small', width_mult=1.0):\n",
    "        super(MobileNetV3, self).__init__()\n",
    "        input_channel = 16\n",
    "        last_channel = 1280\n",
    "        if mode == 'large':\n",
    "            # refer to Table 1 in paper\n",
    "            mobile_setting = [\n",
    "                # k, exp, c,  se,     nl,  s,\n",
    "                [3, 16,  16,  False, 'RE', 1],\n",
    "                [3, 64,  24,  False, 'RE', 2],\n",
    "                [3, 72,  24,  False, 'RE', 1],\n",
    "                [5, 72,  40,  True,  'RE', 2],\n",
    "                [5, 120, 40,  True,  'RE', 1],\n",
    "                [5, 120, 40,  True,  'RE', 1],\n",
    "                [3, 240, 80,  False, 'HS', 2],\n",
    "                [3, 200, 80,  False, 'HS', 1],\n",
    "                [3, 184, 80,  False, 'HS', 1],\n",
    "                [3, 184, 80,  False, 'HS', 1],\n",
    "                [3, 480, 112, True,  'HS', 1],\n",
    "                [3, 672, 112, True,  'HS', 1],\n",
    "                [5, 672, 160, True,  'HS', 2],\n",
    "                [5, 960, 160, True,  'HS', 1],\n",
    "                [5, 960, 160, True,  'HS', 1],\n",
    "            ]\n",
    "        elif mode == 'small':\n",
    "            # refer to Table 2 in paper\n",
    "            mobile_setting = [\n",
    "                # k, exp, c,  se,     nl,  s,\n",
    "                [3, 16,  16,  True,  'RE', 2],\n",
    "                [3, 72,  24,  False, 'RE', 2],\n",
    "                [3, 88,  24,  False, 'RE', 1],\n",
    "                [5, 96,  40,  True,  'HS', 2],\n",
    "                [5, 240, 40,  True,  'HS', 1],\n",
    "                [5, 240, 40,  True,  'HS', 1],\n",
    "                [5, 120, 48,  True,  'HS', 1],\n",
    "                [5, 144, 48,  True,  'HS', 1],\n",
    "                [5, 288, 96,  True,  'HS', 2],\n",
    "                [5, 576, 96,  True,  'HS', 1],\n",
    "                [5, 576, 96,  True,  'HS', 1],\n",
    "            ]\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        # building first layer\n",
    "        assert input_size % 32 == 0\n",
    "        last_channel = make_divisible(last_channel * width_mult) if width_mult > 1.0 else last_channel\n",
    "        self.features = [conv_bn(3, input_channel, 2, nlin_layer=Hswish)]\n",
    "        self.classifier = []\n",
    "\n",
    "        # building mobile blocks\n",
    "        for k, exp, c, se, nl, s in mobile_setting:\n",
    "            output_channel = make_divisible(c * width_mult)\n",
    "            exp_channel = make_divisible(exp * width_mult)\n",
    "            self.features.append(MobileBottleneck(input_channel, output_channel, k, s, exp_channel, se, nl))\n",
    "            input_channel = output_channel\n",
    "\n",
    "        # building last several layers\n",
    "        if mode == 'large':\n",
    "            last_conv = make_divisible(960 * width_mult)\n",
    "            self.features.append(conv_1x1_bn(input_channel, last_conv, nlin_layer=Hswish))\n",
    "            self.features.append(nn.AdaptiveAvgPool2d(1))\n",
    "            self.features.append(nn.Conv2d(last_conv, last_channel, 1, 1, 0))\n",
    "            self.features.append(Hswish(inplace=True))\n",
    "        elif mode == 'small':\n",
    "            last_conv = make_divisible(576 * width_mult)\n",
    "            self.features.append(conv_1x1_bn(input_channel, last_conv, nlin_layer=Hswish))\n",
    "            # self.features.append(SEModule(last_conv))  # refer to paper Table2, but I think this is a mistake\n",
    "            self.features.append(nn.AdaptiveAvgPool2d(1))\n",
    "            self.features.append(nn.Conv2d(last_conv, last_channel, 1, 1, 0))\n",
    "            self.features.append(Hswish(inplace=True))\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        # make it nn.Sequential\n",
    "        self.features = nn.Sequential(*self.features)\n",
    "\n",
    "        # building classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=dropout),    # refer to paper section 6\n",
    "            nn.Linear(last_channel, n_class),\n",
    "        )\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.mean(3).mean(2)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        # weight initialization\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.ones_(m.weight)\n",
    "                nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "\n",
    "\n",
    "def mobilenetv3(pretrained=False, **kwargs):\n",
    "    model = MobileNetV3(**kwargs)\n",
    "    if pretrained:\n",
    "        state_dict = torch.load('mobilenetv3_small_67.4.pth.tar')\n",
    "        model.load_state_dict(state_dict, strict=True)\n",
    "        # raise NotImplementedError\n",
    "    return model\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    net = mobilenetv3()\n",
    "    print('mobilenetv3:\\n', net)\n",
    "    print('Total params: %.2fM' % (sum(p.numel() for p in net.parameters())/1000000.0))\n",
    "    input_size=(1, 3, 224, 224)\n",
    "    # pip install --upgrade git+https://github.com/kuan-wang/pytorch-OpCounter.git\n",
    "    from thop import profile\n",
    "    flops, params = profile(net, input_size=input_size)\n",
    "    # print(flops)\n",
    "    # print(params)\n",
    "    print('Total params: %.2fM' % (params/1000000.0))\n",
    "    print('Total flops: %.2fM' % (flops/1000000.0))\n",
    "    x = torch.randn(input_size)\n",
    "    out = net(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MobileNetV3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(),lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader,model,criterion,optimizer,epoch):\n",
    "    model.train()\n",
    "    for i, (input,target) in enumerate(train_loader):\n",
    "        target = target.to(device)\n",
    "        input = input.to(device)\n",
    "        \n",
    "        output = model(input)\n",
    "        loss = criterion(output,target)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if(i%20 == 0):\n",
    "            print(\"loss in epoch %d , step %d : %f\" % (epoch, i,loss.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(test_loader,model,criterion,epoch):\n",
    "    model.eval()\n",
    "    \n",
    "    correct = 0\n",
    "    \n",
    "    \n",
    "    for i, (input,target) in enumerate(test_loader):\n",
    "        target = target.to(device)\n",
    "        input = input.to(device)\n",
    "        \n",
    "        output = model(input)\n",
    "        loss = criterion(output,target)\n",
    "        \n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().float().sum()\n",
    "    \n",
    "    print(\"Accuracy in epoch %d : %f\" % (epoch,100.0*correct/len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_lr(optimizer, epoch, learning_rate):\n",
    "    if epoch==5 :\n",
    "        learning_rate*=0.1\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 0 , step 0 : 6.970541\n",
      "Accuracy in epoch 0 : 10.089911\n",
      "loss in epoch 1 , step 0 : 5.953565\n",
      "Accuracy in epoch 1 : 9.990010\n",
      "loss in epoch 2 , step 0 : 3.074457\n",
      "Accuracy in epoch 2 : 9.990010\n",
      "loss in epoch 3 , step 0 : 3.054951\n",
      "Accuracy in epoch 3 : 9.990010\n",
      "loss in epoch 4 , step 0 : 0.679957\n",
      "Accuracy in epoch 4 : 9.990010\n",
      "loss in epoch 5 , step 0 : 0.363686\n",
      "Accuracy in epoch 5 : 10.589411\n",
      "loss in epoch 6 , step 0 : 0.255434\n",
      "Accuracy in epoch 6 : 25.974026\n",
      "loss in epoch 7 , step 0 : 0.230825\n",
      "Accuracy in epoch 7 : 56.443558\n",
      "loss in epoch 8 , step 0 : 0.255293\n",
      "Accuracy in epoch 8 : 83.316681\n",
      "loss in epoch 9 , step 0 : 0.202931\n",
      "Accuracy in epoch 9 : 89.810188\n",
      "loss in epoch 10 , step 0 : 0.244208\n",
      "Accuracy in epoch 10 : 92.507492\n",
      "loss in epoch 11 , step 0 : 0.177966\n",
      "Accuracy in epoch 11 : 93.806190\n",
      "loss in epoch 12 , step 0 : 0.195091\n",
      "Accuracy in epoch 12 : 94.905098\n",
      "loss in epoch 13 , step 0 : 0.188140\n",
      "Accuracy in epoch 13 : 94.305695\n",
      "loss in epoch 14 , step 0 : 0.165753\n",
      "Accuracy in epoch 14 : 94.705292\n",
      "loss in epoch 15 , step 0 : 0.251132\n",
      "Accuracy in epoch 15 : 94.105896\n",
      "loss in epoch 16 , step 0 : 0.117572\n",
      "Accuracy in epoch 16 : 94.705292\n",
      "loss in epoch 17 , step 0 : 0.123380\n",
      "Accuracy in epoch 17 : 94.805191\n",
      "loss in epoch 18 , step 0 : 0.104569\n",
      "Accuracy in epoch 18 : 95.304695\n",
      "loss in epoch 19 , step 0 : 0.095045\n",
      "Accuracy in epoch 19 : 95.504494\n",
      "loss in epoch 20 , step 0 : 0.107424\n",
      "Accuracy in epoch 20 : 94.005997\n",
      "loss in epoch 21 , step 0 : 0.071883\n",
      "Accuracy in epoch 21 : 95.204796\n",
      "loss in epoch 22 , step 0 : 0.102332\n",
      "Accuracy in epoch 22 : 94.405594\n",
      "loss in epoch 23 , step 0 : 0.100700\n",
      "Accuracy in epoch 23 : 94.105896\n",
      "loss in epoch 24 , step 0 : 0.080398\n",
      "Accuracy in epoch 24 : 94.405594\n",
      "loss in epoch 25 , step 0 : 0.085245\n",
      "Accuracy in epoch 25 : 95.204796\n",
      "loss in epoch 26 , step 0 : 0.056705\n",
      "Accuracy in epoch 26 : 94.405594\n",
      "loss in epoch 27 , step 0 : 0.064504\n",
      "Accuracy in epoch 27 : 94.205795\n",
      "loss in epoch 28 , step 0 : 0.063460\n",
      "Accuracy in epoch 28 : 95.004997\n",
      "loss in epoch 29 , step 0 : 0.048908\n",
      "Accuracy in epoch 29 : 94.605392\n",
      "loss in epoch 30 , step 0 : 0.056209\n",
      "Accuracy in epoch 30 : 94.905098\n",
      "loss in epoch 31 , step 0 : 0.084416\n",
      "Accuracy in epoch 31 : 94.205795\n",
      "loss in epoch 32 , step 0 : 0.043762\n",
      "Accuracy in epoch 32 : 95.104897\n",
      "loss in epoch 33 , step 0 : 0.057259\n",
      "Accuracy in epoch 33 : 95.104897\n",
      "loss in epoch 34 , step 0 : 0.038351\n",
      "Accuracy in epoch 34 : 95.004997\n",
      "loss in epoch 35 , step 0 : 0.033768\n",
      "Accuracy in epoch 35 : 95.004997\n",
      "loss in epoch 36 , step 0 : 0.038559\n",
      "Accuracy in epoch 36 : 94.805191\n",
      "loss in epoch 37 , step 0 : 0.036438\n",
      "Accuracy in epoch 37 : 94.305695\n",
      "loss in epoch 38 , step 0 : 0.030294\n",
      "Accuracy in epoch 38 : 95.204796\n",
      "loss in epoch 39 , step 0 : 0.035938\n",
      "Accuracy in epoch 39 : 95.004997\n",
      "loss in epoch 40 , step 0 : 0.027820\n",
      "Accuracy in epoch 40 : 94.305695\n",
      "loss in epoch 41 , step 0 : 0.037994\n",
      "Accuracy in epoch 41 : 95.304695\n",
      "loss in epoch 42 , step 0 : 0.030004\n",
      "Accuracy in epoch 42 : 95.304695\n",
      "loss in epoch 43 , step 0 : 0.038957\n",
      "Accuracy in epoch 43 : 95.304695\n",
      "loss in epoch 44 , step 0 : 0.022619\n",
      "Accuracy in epoch 44 : 94.705292\n",
      "loss in epoch 45 , step 0 : 0.028874\n",
      "Accuracy in epoch 45 : 94.505493\n",
      "loss in epoch 46 , step 0 : 0.042591\n",
      "Accuracy in epoch 46 : 95.304695\n",
      "loss in epoch 47 , step 0 : 0.035596\n",
      "Accuracy in epoch 47 : 94.705292\n",
      "loss in epoch 48 , step 0 : 0.026540\n",
      "Accuracy in epoch 48 : 95.504494\n",
      "loss in epoch 49 , step 0 : 0.027619\n",
      "Accuracy in epoch 49 : 95.504494\n",
      "loss in epoch 50 , step 0 : 0.019689\n",
      "Accuracy in epoch 50 : 96.003998\n",
      "loss in epoch 51 , step 0 : 0.017674\n",
      "Accuracy in epoch 51 : 95.804199\n",
      "loss in epoch 52 , step 0 : 0.029172\n",
      "Accuracy in epoch 52 : 95.104897\n",
      "loss in epoch 53 , step 0 : 0.022949\n",
      "Accuracy in epoch 53 : 95.604393\n",
      "loss in epoch 54 , step 0 : 0.021388\n",
      "Accuracy in epoch 54 : 95.504494\n",
      "loss in epoch 55 , step 0 : 0.017620\n",
      "Accuracy in epoch 55 : 95.704292\n",
      "loss in epoch 56 , step 0 : 0.019419\n",
      "Accuracy in epoch 56 : 95.704292\n",
      "loss in epoch 57 , step 0 : 0.027387\n",
      "Accuracy in epoch 57 : 95.804199\n",
      "loss in epoch 58 , step 0 : 0.018613\n",
      "Accuracy in epoch 58 : 94.605392\n",
      "loss in epoch 59 , step 0 : 0.023588\n",
      "Accuracy in epoch 59 : 95.904099\n",
      "loss in epoch 60 , step 0 : 0.021959\n",
      "Accuracy in epoch 60 : 95.604393\n",
      "loss in epoch 61 , step 0 : 0.023563\n",
      "Accuracy in epoch 61 : 94.605392\n",
      "loss in epoch 62 , step 0 : 0.023269\n",
      "Accuracy in epoch 62 : 96.203796\n",
      "loss in epoch 63 , step 0 : 0.013936\n",
      "Accuracy in epoch 63 : 94.905098\n",
      "loss in epoch 64 , step 0 : 0.019816\n",
      "Accuracy in epoch 64 : 94.905098\n",
      "loss in epoch 65 , step 0 : 0.016032\n",
      "Accuracy in epoch 65 : 95.204796\n",
      "loss in epoch 66 , step 0 : 0.023029\n",
      "Accuracy in epoch 66 : 94.905098\n",
      "loss in epoch 67 , step 0 : 0.020510\n",
      "Accuracy in epoch 67 : 95.304695\n",
      "loss in epoch 68 , step 0 : 0.018814\n",
      "Accuracy in epoch 68 : 95.704292\n",
      "loss in epoch 69 , step 0 : 0.021830\n",
      "Accuracy in epoch 69 : 95.304695\n",
      "loss in epoch 70 , step 0 : 0.018803\n",
      "Accuracy in epoch 70 : 95.504494\n",
      "loss in epoch 71 , step 0 : 0.025227\n",
      "Accuracy in epoch 71 : 94.905098\n",
      "loss in epoch 72 , step 0 : 0.013724\n",
      "Accuracy in epoch 72 : 95.404594\n",
      "loss in epoch 73 , step 0 : 0.011865\n",
      "Accuracy in epoch 73 : 94.705292\n",
      "loss in epoch 74 , step 0 : 0.014121\n",
      "Accuracy in epoch 74 : 95.004997\n",
      "loss in epoch 75 , step 0 : 0.013920\n",
      "Accuracy in epoch 75 : 95.204796\n",
      "loss in epoch 76 , step 0 : 0.008021\n",
      "Accuracy in epoch 76 : 95.204796\n",
      "loss in epoch 77 , step 0 : 0.013704\n",
      "Accuracy in epoch 77 : 94.805191\n",
      "loss in epoch 78 , step 0 : 0.020542\n",
      "Accuracy in epoch 78 : 95.304695\n",
      "loss in epoch 79 , step 0 : 0.017324\n",
      "Accuracy in epoch 79 : 95.304695\n",
      "loss in epoch 80 , step 0 : 0.009471\n",
      "Accuracy in epoch 80 : 95.604393\n",
      "loss in epoch 81 , step 0 : 0.010783\n",
      "Accuracy in epoch 81 : 94.805191\n",
      "loss in epoch 82 , step 0 : 0.014142\n",
      "Accuracy in epoch 82 : 95.904099\n",
      "loss in epoch 83 , step 0 : 0.015200\n",
      "Accuracy in epoch 83 : 94.405594\n",
      "loss in epoch 84 , step 0 : 0.008573\n",
      "Accuracy in epoch 84 : 95.104897\n",
      "loss in epoch 85 , step 0 : 0.011261\n",
      "Accuracy in epoch 85 : 95.804199\n",
      "loss in epoch 86 , step 0 : 0.010543\n",
      "Accuracy in epoch 86 : 94.405594\n",
      "loss in epoch 87 , step 0 : 0.024789\n",
      "Accuracy in epoch 87 : 96.103897\n",
      "loss in epoch 88 , step 0 : 0.013941\n",
      "Accuracy in epoch 88 : 95.604393\n",
      "loss in epoch 89 , step 0 : 0.009142\n",
      "Accuracy in epoch 89 : 95.404594\n",
      "loss in epoch 90 , step 0 : 0.013332\n",
      "Accuracy in epoch 90 : 95.004997\n",
      "loss in epoch 91 , step 0 : 0.009608\n",
      "Accuracy in epoch 91 : 95.104897\n",
      "loss in epoch 92 , step 0 : 0.012876\n",
      "Accuracy in epoch 92 : 95.804199\n",
      "loss in epoch 93 , step 0 : 0.012003\n",
      "Accuracy in epoch 93 : 95.204796\n",
      "loss in epoch 94 , step 0 : 0.013067\n",
      "Accuracy in epoch 94 : 95.404594\n",
      "loss in epoch 95 , step 0 : 0.013569\n",
      "Accuracy in epoch 95 : 94.905098\n",
      "loss in epoch 96 , step 0 : 0.012358\n",
      "Accuracy in epoch 96 : 95.504494\n",
      "loss in epoch 97 , step 0 : 0.011746\n",
      "Accuracy in epoch 97 : 94.705292\n",
      "loss in epoch 98 , step 0 : 0.010232\n",
      "Accuracy in epoch 98 : 95.104897\n",
      "loss in epoch 99 , step 0 : 0.011428\n",
      "Accuracy in epoch 99 : 95.404594\n",
      "loss in epoch 100 , step 0 : 0.010710\n",
      "Accuracy in epoch 100 : 95.204796\n",
      "loss in epoch 101 , step 0 : 0.015962\n",
      "Accuracy in epoch 101 : 94.605392\n",
      "loss in epoch 102 , step 0 : 0.013936\n",
      "Accuracy in epoch 102 : 94.505493\n",
      "loss in epoch 103 , step 0 : 0.009195\n",
      "Accuracy in epoch 103 : 95.404594\n",
      "loss in epoch 104 , step 0 : 0.016308\n",
      "Accuracy in epoch 104 : 95.504494\n",
      "loss in epoch 105 , step 0 : 0.007279\n",
      "Accuracy in epoch 105 : 96.003998\n",
      "loss in epoch 106 , step 0 : 0.013146\n",
      "Accuracy in epoch 106 : 95.804199\n",
      "loss in epoch 107 , step 0 : 0.008024\n",
      "Accuracy in epoch 107 : 95.704292\n",
      "loss in epoch 108 , step 0 : 0.009235\n",
      "Accuracy in epoch 108 : 95.204796\n",
      "loss in epoch 109 , step 0 : 0.011875\n",
      "Accuracy in epoch 109 : 95.304695\n",
      "loss in epoch 110 , step 0 : 0.005898\n",
      "Accuracy in epoch 110 : 96.003998\n",
      "loss in epoch 111 , step 0 : 0.007982\n",
      "Accuracy in epoch 111 : 95.004997\n",
      "loss in epoch 112 , step 0 : 0.009667\n",
      "Accuracy in epoch 112 : 95.104897\n",
      "loss in epoch 113 , step 0 : 0.006850\n",
      "Accuracy in epoch 113 : 95.604393\n",
      "loss in epoch 114 , step 0 : 0.013063\n",
      "Accuracy in epoch 114 : 95.304695\n",
      "loss in epoch 115 , step 0 : 0.015668\n",
      "Accuracy in epoch 115 : 94.705292\n",
      "loss in epoch 116 , step 0 : 0.010743\n",
      "Accuracy in epoch 116 : 94.605392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 117 , step 0 : 0.008632\n",
      "Accuracy in epoch 117 : 94.905098\n",
      "loss in epoch 118 , step 0 : 0.006689\n",
      "Accuracy in epoch 118 : 95.304695\n",
      "loss in epoch 119 , step 0 : 0.008200\n",
      "Accuracy in epoch 119 : 95.304695\n",
      "loss in epoch 120 , step 0 : 0.008232\n",
      "Accuracy in epoch 120 : 95.504494\n",
      "loss in epoch 121 , step 0 : 0.004816\n",
      "Accuracy in epoch 121 : 95.204796\n",
      "loss in epoch 122 , step 0 : 0.006810\n",
      "Accuracy in epoch 122 : 95.604393\n",
      "loss in epoch 123 , step 0 : 0.007051\n",
      "Accuracy in epoch 123 : 94.905098\n",
      "loss in epoch 124 , step 0 : 0.007792\n",
      "Accuracy in epoch 124 : 96.303696\n",
      "loss in epoch 125 , step 0 : 0.006506\n",
      "Accuracy in epoch 125 : 95.004997\n",
      "loss in epoch 126 , step 0 : 0.005700\n",
      "Accuracy in epoch 126 : 94.805191\n",
      "loss in epoch 127 , step 0 : 0.006605\n",
      "Accuracy in epoch 127 : 94.805191\n",
      "loss in epoch 128 , step 0 : 0.009764\n",
      "Accuracy in epoch 128 : 95.004997\n",
      "loss in epoch 129 , step 0 : 0.009988\n",
      "Accuracy in epoch 129 : 95.704292\n",
      "loss in epoch 130 , step 0 : 0.006709\n",
      "Accuracy in epoch 130 : 95.804199\n",
      "loss in epoch 131 , step 0 : 0.012407\n",
      "Accuracy in epoch 131 : 94.905098\n",
      "loss in epoch 132 , step 0 : 0.006173\n",
      "Accuracy in epoch 132 : 95.004997\n",
      "loss in epoch 133 , step 0 : 0.009030\n",
      "Accuracy in epoch 133 : 95.204796\n",
      "loss in epoch 134 , step 0 : 0.005558\n",
      "Accuracy in epoch 134 : 95.204796\n",
      "loss in epoch 135 , step 0 : 0.007022\n",
      "Accuracy in epoch 135 : 94.805191\n",
      "loss in epoch 136 , step 0 : 0.005675\n",
      "Accuracy in epoch 136 : 95.204796\n",
      "loss in epoch 137 , step 0 : 0.007579\n",
      "Accuracy in epoch 137 : 94.705292\n",
      "loss in epoch 138 , step 0 : 0.007790\n",
      "Accuracy in epoch 138 : 95.404594\n",
      "loss in epoch 139 , step 0 : 0.003795\n",
      "Accuracy in epoch 139 : 95.904099\n",
      "loss in epoch 140 , step 0 : 0.004937\n",
      "Accuracy in epoch 140 : 95.304695\n",
      "loss in epoch 141 , step 0 : 0.010457\n",
      "Accuracy in epoch 141 : 94.905098\n",
      "loss in epoch 142 , step 0 : 0.005771\n",
      "Accuracy in epoch 142 : 95.104897\n",
      "loss in epoch 143 , step 0 : 0.006944\n",
      "Accuracy in epoch 143 : 95.504494\n",
      "loss in epoch 144 , step 0 : 0.008788\n",
      "Accuracy in epoch 144 : 95.404594\n",
      "loss in epoch 145 , step 0 : 0.006243\n",
      "Accuracy in epoch 145 : 95.004997\n",
      "loss in epoch 146 , step 0 : 0.006524\n",
      "Accuracy in epoch 146 : 96.303696\n",
      "loss in epoch 147 , step 0 : 0.004874\n",
      "Accuracy in epoch 147 : 95.904099\n",
      "loss in epoch 148 , step 0 : 0.006246\n",
      "Accuracy in epoch 148 : 95.704292\n",
      "loss in epoch 149 , step 0 : 0.005429\n",
      "Accuracy in epoch 149 : 95.404594\n",
      "loss in epoch 150 , step 0 : 0.006447\n",
      "Accuracy in epoch 150 : 95.204796\n",
      "loss in epoch 151 , step 0 : 0.007329\n",
      "Accuracy in epoch 151 : 95.504494\n",
      "loss in epoch 152 , step 0 : 0.004037\n",
      "Accuracy in epoch 152 : 95.504494\n",
      "loss in epoch 153 , step 0 : 0.004313\n",
      "Accuracy in epoch 153 : 95.204796\n",
      "loss in epoch 154 , step 0 : 0.006626\n",
      "Accuracy in epoch 154 : 95.104897\n",
      "loss in epoch 155 , step 0 : 0.004594\n",
      "Accuracy in epoch 155 : 93.906097\n",
      "loss in epoch 156 , step 0 : 0.006448\n",
      "Accuracy in epoch 156 : 94.405594\n",
      "loss in epoch 157 , step 0 : 0.003614\n",
      "Accuracy in epoch 157 : 96.603394\n",
      "loss in epoch 158 , step 0 : 0.008616\n",
      "Accuracy in epoch 158 : 95.404594\n",
      "loss in epoch 159 , step 0 : 0.007362\n",
      "Accuracy in epoch 159 : 96.003998\n",
      "loss in epoch 160 , step 0 : 0.005665\n",
      "Accuracy in epoch 160 : 95.304695\n",
      "loss in epoch 161 , step 0 : 0.004881\n",
      "Accuracy in epoch 161 : 95.004997\n",
      "loss in epoch 162 , step 0 : 0.004593\n",
      "Accuracy in epoch 162 : 95.804199\n",
      "loss in epoch 163 , step 0 : 0.004806\n",
      "Accuracy in epoch 163 : 94.805191\n",
      "loss in epoch 164 , step 0 : 0.008418\n",
      "Accuracy in epoch 164 : 94.805191\n",
      "loss in epoch 165 , step 0 : 0.006203\n",
      "Accuracy in epoch 165 : 95.704292\n",
      "loss in epoch 166 , step 0 : 0.010360\n",
      "Accuracy in epoch 166 : 95.504494\n",
      "loss in epoch 167 , step 0 : 0.005939\n",
      "Accuracy in epoch 167 : 95.404594\n",
      "loss in epoch 168 , step 0 : 0.003560\n",
      "Accuracy in epoch 168 : 95.104897\n",
      "loss in epoch 169 , step 0 : 0.009216\n",
      "Accuracy in epoch 169 : 94.705292\n",
      "loss in epoch 170 , step 0 : 0.007752\n",
      "Accuracy in epoch 170 : 96.403595\n",
      "loss in epoch 171 , step 0 : 0.006012\n",
      "Accuracy in epoch 171 : 95.904099\n",
      "loss in epoch 172 , step 0 : 0.005674\n",
      "Accuracy in epoch 172 : 96.003998\n",
      "loss in epoch 173 , step 0 : 0.006228\n",
      "Accuracy in epoch 173 : 96.003998\n",
      "loss in epoch 174 , step 0 : 0.007269\n",
      "Accuracy in epoch 174 : 96.303696\n",
      "loss in epoch 175 , step 0 : 0.002873\n",
      "Accuracy in epoch 175 : 95.504494\n",
      "loss in epoch 176 , step 0 : 0.005824\n",
      "Accuracy in epoch 176 : 95.004997\n",
      "loss in epoch 177 , step 0 : 0.004040\n",
      "Accuracy in epoch 177 : 95.304695\n",
      "loss in epoch 178 , step 0 : 0.005219\n",
      "Accuracy in epoch 178 : 95.504494\n",
      "loss in epoch 179 , step 0 : 0.004059\n",
      "Accuracy in epoch 179 : 95.404594\n",
      "loss in epoch 180 , step 0 : 0.005501\n",
      "Accuracy in epoch 180 : 95.204796\n",
      "loss in epoch 181 , step 0 : 0.007991\n",
      "Accuracy in epoch 181 : 95.904099\n",
      "loss in epoch 182 , step 0 : 0.005016\n",
      "Accuracy in epoch 182 : 95.304695\n",
      "loss in epoch 183 , step 0 : 0.003574\n",
      "Accuracy in epoch 183 : 95.404594\n",
      "loss in epoch 184 , step 0 : 0.004492\n",
      "Accuracy in epoch 184 : 95.504494\n",
      "loss in epoch 185 , step 0 : 0.006655\n",
      "Accuracy in epoch 185 : 95.704292\n",
      "loss in epoch 186 , step 0 : 0.004051\n",
      "Accuracy in epoch 186 : 96.203796\n",
      "loss in epoch 187 , step 0 : 0.002953\n",
      "Accuracy in epoch 187 : 94.805191\n",
      "loss in epoch 188 , step 0 : 0.003725\n",
      "Accuracy in epoch 188 : 95.704292\n",
      "loss in epoch 189 , step 0 : 0.005143\n",
      "Accuracy in epoch 189 : 95.504494\n",
      "loss in epoch 190 , step 0 : 0.004680\n",
      "Accuracy in epoch 190 : 94.905098\n",
      "loss in epoch 191 , step 0 : 0.003501\n",
      "Accuracy in epoch 191 : 95.204796\n",
      "loss in epoch 192 , step 0 : 0.008158\n",
      "Accuracy in epoch 192 : 95.304695\n",
      "loss in epoch 193 , step 0 : 0.015864\n",
      "Accuracy in epoch 193 : 94.605392\n",
      "loss in epoch 194 , step 0 : 0.005691\n",
      "Accuracy in epoch 194 : 95.104897\n",
      "loss in epoch 195 , step 0 : 0.004028\n",
      "Accuracy in epoch 195 : 95.204796\n",
      "loss in epoch 196 , step 0 : 0.003893\n",
      "Accuracy in epoch 196 : 94.905098\n",
      "loss in epoch 197 , step 0 : 0.004358\n",
      "Accuracy in epoch 197 : 95.104897\n",
      "loss in epoch 198 , step 0 : 0.002954\n",
      "Accuracy in epoch 198 : 95.004997\n",
      "loss in epoch 199 , step 0 : 0.006664\n",
      "Accuracy in epoch 199 : 95.904099\n",
      "loss in epoch 200 , step 0 : 0.004117\n",
      "Accuracy in epoch 200 : 94.905098\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(0,201):\n",
    "    adjust_lr(optimizer,epoch,learning_rate)\n",
    "    train(train_loader,model,criterion,optimizer,epoch)\n",
    "    test(test_loader,model,criterion,epoch)\n",
    "    if epoch % 1 == 0: #1회당 한번저장\n",
    "        torch.save(model.state_dict(), model_weight_save_path + 'model.pt', _use_new_zipfile_serialization=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
